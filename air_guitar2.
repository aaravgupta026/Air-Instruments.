import mediapipe as mp
import cv2
import numpy as np
import threading
import playsound
import random

mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands

def decide_gesture(inout_list):
    gestures = {
        (True, False, True, True, True): 'one',
        (True, False, False, True, True): 'two',
        (True, False, False, False, True): 'three',
        (True, False, False, False, False): 'four',
        (False, False, False, False, False): 'five',
        (False, True, True, True, False): 'six',
        (False, False, True, True, True): 'seven',
        (False, False, False, True, True): 'eight',
        (True, False, True, True, False): 'rock1',
        (False, False, True, True, False): 'rock2',
    }
    return gestures.get(tuple(inout_list), None)

def formula_big(x1, x2, x3, y1, y2, y3):
    mul_x, mul_y = 640, 480
    x1, x2, x3 = x1 * mul_x, x2 * mul_x, x3 * mul_x
    y1, y2, y3 = y1 * mul_y, y2 * mul_y, y3 * mul_y
    a = (y1 - y2) / (x1 - x2)
    b = y1 - a * x1
    if x1 > x2:
        return x3 * a + b > y3 - abs(x1 - x2 + y1 - y2)
    return x3 * a + b <= y3


def draw_and_get_finger_angles(image, results):
    for hand in results.multi_hand_landmarks:
        a = np.array([hand.landmark[4].x, hand.landmark[4].y])
        b = np.array([hand.landmark[8].x, hand.landmark[8].y])
        c = np.array([hand.landmark[12].x, hand.landmark[12].y])
        d = np.array([hand.landmark[16].x, hand.landmark[16].y])
        e = np.array([hand.landmark[20].x, hand.landmark[20].y])
        
        inout_list = [
            formula_big(f[0], j[0], a[0], f[1], j[1], a[1]),
            not formula_other(f[0], np.array([hand.landmark[9].x, hand.landmark[9].y])[0], b[0], f[1], np.array([hand.landmark[9].y, hand.landmark[9].y])[1], b[1]),
            not formula_other(f[0], np.array([hand.landmark[9].x, hand.landmark[9].y])[0], c[0], f[1], np.array([hand.landmark[9].y, hand.landmark[9].y])[1], c[1]),
            not formula_other(f[0], np.array([hand.landmark[9].x, hand.landmark[9].y])[0], d[0], f[1], np.array([hand.landmark[9].y, hand.landmark[9].y])[1], d[1]),
            not formula_other(f[0], np.array([hand.landmark[9].x, hand.landmark[9].y])[0], e[0], f[1], np.array([hand.landmark[9].y, hand.landmark[9].y])[1], e[1]),
        ]
        cv2.putText(image, " ".join(str(x) for x in inout_list), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)
        gesture = decide_gesture(inout_list)
        return image, gesture

def play_chord(chord):
    threading.Thread(target=playsound.playsound, args=(f'music/{chord}.mp3',)).start()

chord_modes = [
    {'one': "C_chord", 'two': "A_chord", 'three': "D_chord", 'four': "G_chord", 'eight': "applaud"},
]

def change_chord_mode(mode):
    return (mode + 1) % len(chord_modes)

cap = cv2.VideoCapture(0)
counter, chord_mode, status, previous_gesture = 0, 0, "up", None

with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:
    while cap.isOpened():
        ret, frame = cap.read()
        cv2.namedWindow("Hand Tracking", 0)
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image = cv2.flip(image, 1)
        image.flags.writeable = False
        results = hands.process(image)
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        if results.multi_hand_landmarks:
            for hand in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS)
                image, gesture_left = draw_and_get_finger_angles(image, results)
        
        if gesture_left and counter > 20:
            previous_gesture = gesture_left
            counter = 0

        try:
            is_inside = formula_big(left_MIDDLE_FINGER_MCP[0], 640, right_INEDX_FINGER_DIP[0], left_MIDDLE_FINGER_MCP[1], 480, right_INEDX_FINGER_DIP[1])
            if gesture_left and is_inside and status == "up" and distance > 0.4:
                play_chord(chord_modes[chord_mode][gesture_left])
                counter = 0
                status = "down"
            elif gesture_left and not is_inside and status == "down" and distance > 0.4:
                play_chord(chord_modes[chord_mode][gesture_left])
                counter = 0
                status = "up"


        cv2.putText(image, f'chord mode: {chord_mode}', (380, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)
        cv2.resizeWindow("Hand Tracking", 1280, 960)
        cv2.imshow('Hand Tracking', image)

        if cv2.waitKey(10) & 0xFF == ord('q'):
            break

        counter += 1

cap.release()
cv2.destroyAllWindows()
